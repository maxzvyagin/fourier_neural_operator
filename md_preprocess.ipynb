{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f00aeb7",
   "metadata": {},
   "source": [
    "# Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "776d8cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TYPE_CHECKING, Tuple, Union, Optional\n",
    "from pathlib import Path\n",
    "\n",
    "if TYPE_CHECKING:\n",
    "    import numpy.typing as npt\n",
    "\n",
    "import h5py  # type: ignore[import]\n",
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix  # type: ignore[import]\n",
    "from tqdm import tqdm\n",
    "\n",
    "PathLike = Union[Path, str]\n",
    "\n",
    "\n",
    "def sparse_to_dense(\n",
    "    h5_file: PathLike,\n",
    "    dataset_name: str,\n",
    "    initial_shape: Tuple[int, int],\n",
    "    final_shape: Union[Tuple[int, int, int], Tuple[int, int]],\n",
    "    values_dataset_name: Optional[str] = None,\n",
    ") -> \"npt.ArrayLike\":\n",
    "    \"\"\"Convert sparse COO formatted contact maps to dense.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    h5_file : PathLike\n",
    "        The HDF5 file containing contact maps.\n",
    "    dataset_name : str\n",
    "        The dataset name containing the contact map indices.\n",
    "    initial_shape : Tuple[int, int]\n",
    "        The shape of the contact map saved in the HDF5 file.\n",
    "    final_shape : Union[Tuple[int, int, int], Tuple[int, int]]\n",
    "        The final shape of the contact map incase adding an extra\n",
    "        dimension is necessary e.g. (D, D, 1) where D is the number\n",
    "        of residues or the cropping shape.\n",
    "    values_dataset_name: Optional[str], default=None\n",
    "        Name of dataset containing the values of the sparse matrix.\n",
    "        By default, it autofills with 1.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    npt.ArrayLike\n",
    "        The output array of contact maps of shape (N, D, D) or\n",
    "        (N, D, D, 1) depending on :obj:`final_shape` where N is\n",
    "        the number of contact maps in the HDF5 file.\n",
    "    \"\"\"\n",
    "    contact_maps = []\n",
    "    with h5py.File(h5_file, \"r\", libver=\"latest\", swmr=False) as f:\n",
    "        \n",
    "        # Read all data into memory at once\n",
    "        dataset = f[dataset_name][...]\n",
    "        if values_dataset_name is not None:\n",
    "            values_dataset = f[values_dataset_name][...]\n",
    "        \n",
    "        for i, raw_indices in tqdm(enumerate(dataset)):\n",
    "            indices = raw_indices.reshape((2, -1)).astype(\"int16\")\n",
    "            \n",
    "            if values_dataset_name is None:\n",
    "                # Contact matrices are binary so we don't need to store the values\n",
    "                # in HDF5 format. Instead we create a vector of 1s on the fly.\n",
    "                values = np.ones(indices.shape[1]).astype(\"byte\")\n",
    "            else:\n",
    "                values = values_dataset[i]\n",
    "\n",
    "            # Construct COO formated sparse matrix\n",
    "            contact_map = coo_matrix(\n",
    "                (values, (indices[0], indices[1])), shape=initial_shape\n",
    "            ).todense()\n",
    "            # Crop and reshape incase of extra 1 e.g. (N, N, 1)\n",
    "            contact_map = np.array(\n",
    "                contact_map[: final_shape[0], : final_shape[1]], dtype=np.float16\n",
    "            ).reshape(final_shape)\n",
    "            contact_maps.append(contact_map)\n",
    "    return np.array(contact_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "326d60df",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1169934/239392261.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m contact_maps = sparse_to_dense(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mh5_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/lambda_stor/homes/abrace/data/bba/1FME-0.h5\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mdataset_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"contact_map\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0minitial_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mfinal_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1169934/311928628.py\u001b[0m in \u001b[0;36msparse_to_dense\u001b[0;34m(h5_file, dataset_name, initial_shape, final_shape, values_dataset_name)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# Read all data into memory at once\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalues_dataset_name\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mvalues_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalues_dataset_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fno/lib/python3.9/site-packages/h5py/_hl/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, args, new_dtype)\u001b[0m\n\u001b[1;32m    781\u001b[0m         \u001b[0mmspace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_simple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m         \u001b[0mfspace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdxpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dxpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    784\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m         \u001b[0;31m# Patch up the output for NumPy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5d.pyx\u001b[0m in \u001b[0;36mh5py.h5d.DatasetID.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_proxy.pyx\u001b[0m in \u001b[0;36mh5py._proxy.dset_rw\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_conv.pyx\u001b[0m in \u001b[0;36mh5py._conv.vlen2ndarray\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5t.pyx\u001b[0m in \u001b[0;36mh5py.h5t.TypeID.dtype.__get__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5t.pyx\u001b[0m in \u001b[0;36mh5py.h5t.TypeID.dtype.__get__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5t.pyx\u001b[0m in \u001b[0;36mh5py.h5t.TypeIntegerID.py_dtype\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "contact_maps = sparse_to_dense(\n",
    "    h5_file=\"/lambda_stor/homes/abrace/data/bba/1FME-0.h5\",\n",
    "    dataset_name=\"contact_map\",\n",
    "    initial_shape=(28, 28),\n",
    "    final_shape=(28, 28),\n",
    "    values_dataset_name=\"contact_map_values\",\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ae088c-d670-4ecc-a8da-2415d3b7925b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.ones((28, 28))\n",
    "for i in range(28):\n",
    "    try:\n",
    "        mask[i][i+1] = 0\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        mask[i][i-1] = 0\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        mask[i][i+2] = 0\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        mask[i][i-2] = 0\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68e0c03-6b9b-4f26-bded-2ea3ec88b352",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask[0][26] = 1\n",
    "mask[0][27] = 1\n",
    "mask[1][27] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "930a631c-7df0-4ac9-a5fc-07c8a0afdbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00612adc-487f-4e29-87cb-f73581279290",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79365bb5-6de3-4e6e-8875-07cdb86e0470",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mask' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1169934/1308882499.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'mask' is not defined"
     ]
    }
   ],
   "source": [
    "plt.imshow(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa2ca17-2b39-4c46-b9d2-581d4cfc045f",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_contact_maps = np.array([cm * mask for cm in contact_maps])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edc510b-15fd-448d-b621-e46aeebdf5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(cm):\n",
    "    for i in range(28):\n",
    "        for j in range(28):\n",
    "            diff = abs(i-j)\n",
    "            cm[i][j] *= diff\n",
    "    return cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cd7aa6-48ec-4bea-b5e6-8e9460934682",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_contact_maps = np.array([scale(cm) for cm in tqdm(contact_maps)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c018b40-abf1-4d3d-aa5d-efd163c6816c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_contact_maps = np.load('scaled_contact_maps.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259a3bd7-5bd6-4ece-856d-7250a8f56407",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(scaled_contact_maps[0].astype(\"float32\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2bc299",
   "metadata": {},
   "outputs": [],
   "source": [
    "contact_maps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1776f4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f57a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(contact_maps[::1].astype(\"float32\").reshape(28*28, -1), aspect='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef90fe69-61d3-4d2f-afc4-248a35213145",
   "metadata": {},
   "outputs": [],
   "source": [
    "contact_maps = scaled_contact_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957697c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To input to FNO, the data must have shape (N, 28, 28, T)\n",
    "# Pick T=50, to mimic the 2D Navier-Stokes equation example\n",
    "# found here: https://github.com/zongyi-li/fourier_neural_operator/tree/master\n",
    "\n",
    "T = 100 # Number of time steps per example\n",
    "M = contact_maps.shape[1] # Number of residues\n",
    "N = len(contact_maps) # Total number of contact maps\n",
    "\n",
    "print(T, M, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f648cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fno_input = np.array([contact_maps[i * T: (i + 1) * T] for i in range(N // T)]).astype(\"float32\")\n",
    "fno_input = np.swapaxes(fno_input, 1, 3)\n",
    "fno_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9925834b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(\"bba_fno_input.npy\", fno_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fae91c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fno_input = np.load(\"bba_fno_input.npy\").astype(\"float32\")\n",
    "# fno_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4370d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take Every other residue to get (N, 14, 14, 50)\n",
    "# Then test super resolution on (N, 28, 28, 50)\n",
    "\n",
    "# Then test time-super-resolution\n",
    "# Train on: (N, 28, 28, 50)\n",
    "# Test on: (N, 28, 28, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c73d5a",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b7c8bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "@author: Zongyi Li\n",
    "This file is the Fourier Neural Operator for 2D problem such as the Navier-Stokes equation discussed in Section 5.3 in the [paper](https://arxiv.org/pdf/2010.08895.pdf),\n",
    "which uses a recurrent structure to propagates in time.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from utilities3 import *\n",
    "\n",
    "import operator\n",
    "from functools import reduce\n",
    "from functools import partial\n",
    "\n",
    "from timeit import default_timer\n",
    "\n",
    "from Adam import Adam\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "################################################################\n",
    "# fourier layer\n",
    "################################################################\n",
    "\n",
    "class SpectralConv2d_fast(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, modes1, modes2):\n",
    "        super(SpectralConv2d_fast, self).__init__()\n",
    "\n",
    "        \"\"\"\n",
    "        2D Fourier layer. It does FFT, linear transform, and Inverse FFT.    \n",
    "        \"\"\"\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.modes1 = modes1 #Number of Fourier modes to multiply, at most floor(N/2) + 1\n",
    "        self.modes2 = modes2\n",
    "\n",
    "        self.scale = (1 / (in_channels * out_channels))\n",
    "        self.weights1 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, dtype=torch.cfloat))\n",
    "        self.weights2 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, dtype=torch.cfloat))\n",
    "\n",
    "    # Complex multiplication\n",
    "    def compl_mul2d(self, input, weights):\n",
    "        # (batch, in_channel, x,y ), (in_channel, out_channel, x,y) -> (batch, out_channel, x,y)\n",
    "        return torch.einsum(\"bixy,ioxy->boxy\", input, weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.shape[0]\n",
    "        #Compute Fourier coeffcients up to factor of e^(- something constant)\n",
    "        x_ft = torch.fft.rfft2(x)\n",
    "\n",
    "        # Multiply relevant Fourier modes\n",
    "        out_ft = torch.zeros(batchsize, self.out_channels,  x.size(-2), x.size(-1)//2 + 1, dtype=torch.cfloat, device=x.device)\n",
    "        out_ft[:, :, :self.modes1, :self.modes2] = \\\n",
    "            self.compl_mul2d(x_ft[:, :, :self.modes1, :self.modes2], self.weights1)\n",
    "        out_ft[:, :, -self.modes1:, :self.modes2] = \\\n",
    "            self.compl_mul2d(x_ft[:, :, -self.modes1:, :self.modes2], self.weights2)\n",
    "\n",
    "        #Return to physical space\n",
    "        x = torch.fft.irfft2(out_ft, s=(x.size(-2), x.size(-1)))\n",
    "        return x\n",
    "\n",
    "class FNO2d(nn.Module):\n",
    "    def __init__(self, modes1, modes2, width, timesteps: int):\n",
    "        super(FNO2d, self).__init__()\n",
    "\n",
    "        \"\"\"\n",
    "        The overall network. It contains 4 layers of the Fourier layer.\n",
    "        1. Lift the input to the desire channel dimension by self.fc0 .\n",
    "        2. 4 layers of the integral operators u' = (W + K)(u).\n",
    "            W defined by self.w; K defined by self.conv .\n",
    "        3. Project from the channel space to the output space by self.fc1 and self.fc2 .\n",
    "        \n",
    "        input: the solution of the previous 10 timesteps + 2 locations (u(t-10, x, y), ..., u(t-1, x, y),  x, y)\n",
    "        input shape: (batchsize, x=64, y=64, c=12)\n",
    "        output: the solution of the next timestep\n",
    "        output shape: (batchsize, x=64, y=64, c=1)\n",
    "        \"\"\"\n",
    "\n",
    "        self.modes1 = modes1\n",
    "        self.modes2 = modes2\n",
    "        self.width = width\n",
    "        self.padding = 2 # pad the domain if input is non-periodic\n",
    "        #self.fc0 = nn.Linear(12, self.width)\n",
    "        # +2 because the grid (we think)\n",
    "        self.fc0 = nn.Linear(timesteps + 2, self.width)\n",
    "        # input channel is 12: the solution of the previous 10 timesteps + 2 locations (u(t-10, x, y), ..., u(t-1, x, y),  x, y)\n",
    "\n",
    "        self.conv0 = SpectralConv2d_fast(self.width, self.width, self.modes1, self.modes2)\n",
    "        self.conv1 = SpectralConv2d_fast(self.width, self.width, self.modes1, self.modes2)\n",
    "        self.conv2 = SpectralConv2d_fast(self.width, self.width, self.modes1, self.modes2)\n",
    "        self.conv3 = SpectralConv2d_fast(self.width, self.width, self.modes1, self.modes2)\n",
    "        self.w0 = nn.Conv2d(self.width, self.width, 1)\n",
    "        self.w1 = nn.Conv2d(self.width, self.width, 1)\n",
    "        self.w2 = nn.Conv2d(self.width, self.width, 1)\n",
    "        self.w3 = nn.Conv2d(self.width, self.width, 1)\n",
    "        self.bn0 = torch.nn.BatchNorm2d(self.width)\n",
    "        self.bn1 = torch.nn.BatchNorm2d(self.width)\n",
    "        self.bn2 = torch.nn.BatchNorm2d(self.width)\n",
    "        self.bn3 = torch.nn.BatchNorm2d(self.width)\n",
    "\n",
    "        self.fc1 = nn.Linear(self.width, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        grid = self.get_grid(x.shape, x.device)\n",
    "        x = torch.cat((x, grid), dim=-1)\n",
    "        x = self.fc0(x)\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        # x = F.pad(x, [0,self.padding, 0,self.padding]) # pad the domain if input is non-periodic\n",
    "\n",
    "        x1 = self.conv0(x)\n",
    "        x2 = self.w0(x)\n",
    "        x = x1 + x2\n",
    "        x = F.gelu(x)\n",
    "\n",
    "        x1 = self.conv1(x)\n",
    "        x2 = self.w1(x)\n",
    "        x = x1 + x2\n",
    "        x = F.gelu(x)\n",
    "\n",
    "        x1 = self.conv2(x)\n",
    "        x2 = self.w2(x)\n",
    "        x = x1 + x2\n",
    "        x = F.gelu(x)\n",
    "\n",
    "        x1 = self.conv3(x)\n",
    "        x2 = self.w3(x)\n",
    "        x = x1 + x2\n",
    "\n",
    "        # x = x[..., :-self.padding, :-self.padding] # pad the domain if input is non-periodic\n",
    "        x = x.permute(0, 2, 3, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "    def get_grid(self, shape, device):\n",
    "        batchsize, size_x, size_y = shape[0], shape[1], shape[2]\n",
    "        gridx = torch.tensor(np.linspace(0, 1, size_x), dtype=torch.float)\n",
    "        gridx = gridx.reshape(1, size_x, 1, 1).repeat([batchsize, 1, size_y, 1])\n",
    "        gridy = torch.tensor(np.linspace(0, 1, size_y), dtype=torch.float)\n",
    "        gridy = gridy.reshape(1, 1, size_y, 1).repeat([batchsize, size_x, 1, 1])\n",
    "        return torch.cat((gridx, gridy), dim=-1).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babce0e1-feda-423d-b50f-27f933f28140",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fno_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c62fb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ntrain = 17832\n",
    "# ntest = 4457\n",
    "\n",
    "modes = 12\n",
    "width = 20 # 25 + 25, this also doesn't work\n",
    "\n",
    "batch_size = 128\n",
    "batch_size2 = batch_size\n",
    "\n",
    "epochs = 10\n",
    "learning_rate = 0.001\n",
    "scheduler_step = 100\n",
    "scheduler_gamma = 0.5\n",
    "\n",
    "sub = 1\n",
    "S = 28\n",
    "T_in = 50\n",
    "T = 50\n",
    "step = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d75c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "fno_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfd3965",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split_ptc = 0.8\n",
    "fno_input_train = fno_input[: int(train_split_ptc * len(fno_input))]\n",
    "fno_input_test = fno_input[: int((1- train_split_ptc) * len(fno_input))]\n",
    "print(fno_input_train.shape)\n",
    "print(fno_input_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1148dbcb-c9af-43ff-879d-16ce75bf8cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrain = len(fno_input_train)\n",
    "ntest = len(fno_input_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b344803b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_a = fno_input_train[:ntrain,::sub,::sub,:T_in]\n",
    "train_u = fno_input_train[:ntrain,::sub,::sub,T_in:T+T_in]\n",
    "\n",
    "test_a = fno_input_test[-ntest:,::sub,::sub,:T_in]\n",
    "test_u = fno_input_test[-ntest:,::sub,::sub,T_in:T+T_in]\n",
    "\n",
    "print(train_a.shape)\n",
    "print(train_u.shape)\n",
    "\n",
    "print(test_a.shape)\n",
    "print(test_u.shape)\n",
    "\n",
    "assert (S == train_u.shape[-2])\n",
    "assert (T == train_u.shape[-1])\n",
    "\n",
    "train_a = torch.from_numpy(train_a)\n",
    "train_u = torch.from_numpy(train_u)\n",
    "test_a = torch.from_numpy(test_a)\n",
    "test_u = torch.from_numpy(test_u)\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(train_a, train_u)\n",
    "test_dataset = torch.utils.data.TensorDataset(test_a, test_u)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True, drop_last=True\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=batch_size, shuffle=False, drop_last=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d543508a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FNO2d(modes, modes, width, T_in).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d370da",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87aef9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(count_params(model))\n",
    "optimizer = Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=scheduler_step, gamma=scheduler_gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fefabc-eca6-4067-be8b-2a35d28e88fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54938d2c-72ea-406c-89bb-e63d0c12155d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6daa8f18-6716-4337-b225-93fe93fa31f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project=\"fourier_neural_operator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02575023",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "myloss = LpLoss(size_average=False)\n",
    "for ep in range(epochs):\n",
    "    model.train()\n",
    "    t1 = default_timer()\n",
    "    train_l2_step = 0\n",
    "    train_l2_full = 0\n",
    "    for xx, yy in train_loader:\n",
    "        loss = 0\n",
    "        xx = xx.to(device)\n",
    "        yy = yy.to(device)\n",
    "\n",
    "        for t in range(0, T, step):\n",
    "            y = yy[..., t:t + step]\n",
    "            im = model(xx)\n",
    "            loss += myloss(im.reshape(batch_size, -1), y.reshape(batch_size, -1))\n",
    "\n",
    "            if t == 0:\n",
    "                pred = im\n",
    "            else:\n",
    "                pred = torch.cat((pred, im), -1)\n",
    "\n",
    "            xx = torch.cat((xx[..., step:], im), dim=-1)\n",
    "\n",
    "        train_l2_step += loss.item()\n",
    "        l2_full = myloss(pred.reshape(batch_size, -1), yy.reshape(batch_size, -1))\n",
    "        train_l2_full += l2_full.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    test_l2_step = 0\n",
    "    test_l2_full = 0\n",
    "    with torch.no_grad():\n",
    "        for xx, yy in test_loader:\n",
    "            loss = 0\n",
    "            xx = xx.to(device)\n",
    "            yy = yy.to(device)\n",
    "\n",
    "            for t in range(0, T, step):\n",
    "                y = yy[..., t:t + step]\n",
    "                im = model(xx)\n",
    "                loss += myloss(im.reshape(batch_size, -1), y.reshape(batch_size, -1))\n",
    "\n",
    "                if t == 0:\n",
    "                    pred = im\n",
    "                else:\n",
    "                    pred = torch.cat((pred, im), -1)\n",
    "\n",
    "                xx = torch.cat((xx[..., step:], im), dim=-1)\n",
    "\n",
    "            test_l2_step += loss.item()\n",
    "            test_l2_full += myloss(pred.reshape(batch_size, -1), yy.reshape(batch_size, -1)).item()\n",
    "\n",
    "    t2 = default_timer()\n",
    "    scheduler.step()\n",
    "    results_dir = {}\n",
    "    results_dir['time'] = t2-t1\n",
    "    results_dir['train_l2_step'] = train_l2_step / ntrain / (T / step)\n",
    "    results_dir['train_l2_full'] = train_l2_full / ntrain\n",
    "    results_dir['test_l2_step'] = test_l2_step / ntest / (T / step)\n",
    "    results_dir['test_l2_full'] = test_l2_full / ntest\n",
    "    wandb.log(results_dir)\n",
    "    print(ep, t2 - t1, train_l2_step / ntrain / (T / step), train_l2_full / ntrain, test_l2_step / ntest / (T / step),\n",
    "          test_l2_full / ntest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0f4179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate figure 1\n",
    "# relative error wrt epoch (loss curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95f5378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distance values\n",
    "epoch_prints = \"\"\"0 42.81092274095863 0.4937476319783255 0.49396123154487453 0.48304816554366725 0.48347714847584383\n",
    "1 41.74038385390304 0.4777162232704899 0.47219856719149234 0.46731318668316696 0.448610972951607\n",
    "2 41.10376914800145 0.45782351097219887 0.4461775643240448 0.44931102496774733 0.4416411898182678\n",
    "3 42.039382281014696 0.4332405357994055 0.4304912185497806 0.42747499325148647 0.426015575289967\n",
    "4 45.02936312719248 0.4182806662092727 0.42260830538216165 0.4194621127930783 0.42533674404870936\n",
    "5 44.74461394106038 0.4127451915578384 0.42118305430491443 0.41579025751276083 0.42233645597701386\n",
    "6 45.01867930404842 0.4097005712167732 0.42020176792957686 0.4129501061357135 0.4239311500705088\n",
    "7 44.43967142398469 0.4075468456461698 0.4196401243522168 0.4122257912413058 0.4197785033221092\n",
    "8 44.88021915103309 0.40621104976744754 0.41869536468724916 0.410547168604162 0.42362749777167585\n",
    "9 43.28271347400732 0.40488185959581086 0.41826833636838795 0.4093319146847655 0.4232965819846896\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b80fc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "logs = defaultdict(list)\n",
    "for line in epoch_prints.split(\"\\n\"):\n",
    "    epoch, time, train_l2_step, train_l2_full, test_l2_step, test_l2_full = line.split()\n",
    "    logs[\"epoch\"].append(int(epoch))\n",
    "    logs[\"time\"].append(float(time))\n",
    "    logs[\"train_l2_step\"].append(float(train_l2_step))\n",
    "    logs[\"train_l2_full\"].append(float(train_l2_full))\n",
    "    logs[\"test_l2_step\"].append(float(test_l2_step))\n",
    "    logs[\"test_l2_full\"].append(float(test_l2_full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f657f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c06bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(kind=\"line\", x=\"epoch\", y=\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ce81ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(kind=\"line\", x=\"epoch\", y=[\"train_l2_step\", \"test_l2_step\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c213660",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(kind=\"line\", x=\"epoch\", y=[\"train_l2_full\", \"test_l2_full\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34141e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "yy_s = []\n",
    "def inference(model, test_loader, T: int, step: int, batch_size: int):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for xx, yy in test_loader:\n",
    "            loss = 0\n",
    "            xx = xx.to(device)\n",
    "            yy = yy.to(device)\n",
    "            yy_s.append(yy)\n",
    "            for t in range(0, T, step):\n",
    "                y = yy[..., t:t + step]\n",
    "#                 print(y.shape)\n",
    "                im = model(xx)\n",
    "                loss += myloss(im.reshape(batch_size, -1), y.reshape(batch_size, -1))\n",
    "\n",
    "                if t == 0:\n",
    "                    pred = im\n",
    "                else:\n",
    "                    pred = torch.cat((pred, im), -1)\n",
    "#                     print(pred.shape)\n",
    "\n",
    "                xx = torch.cat((xx[..., step:], im), dim=-1)\n",
    "#                 print(xx.shape)\n",
    "            preds.append(pred)\n",
    "#             print(xx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1c3f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference(model, test_loader, T, step, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd6be1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d90c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51d50e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = np.dsplit(yy_s[0][0].cpu(), 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25ebff8-891c-4fe1-88ae-0926d3e93eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d84e4b-8ea6-499d-9fea-bd02fdb1b334",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.contourf(frames[0].squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab3867a-2e48-49e5-9856-327555cb3cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(frames[1].squeeze().numpy().astype(\"float32\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e9e675-b2ef-4faa-82ba-e259690f1425",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fb7ca0-f8a6-42fa-a206-45b3f0e6db89",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.axes(xlim=(0, 28), ylim=(0, 28))\n",
    "\n",
    "def animate(i):\n",
    "    ax.clear()\n",
    "    ax.imshow(frames[i].squeeze().numpy().astype(\"float32\"))\n",
    "\n",
    "anim = FuncAnimation(fig, animate, frames=50, blit=False)\n",
    "# anim.save('/homes/mzvyagin/labels_slow_imshow.mp4', fps=5, extra_args=['-vcodec', 'libx264'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7ae2e2-4437-4c3b-8254-19af6d709313",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
